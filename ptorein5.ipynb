{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ptorein5.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["wGePhRqjtG3y","QH3r1Jqjc-bJ"]}},"cells":[{"metadata":{"id":"xKk4yW4xbdWd","colab_type":"text"},"cell_type":"markdown","source":["transfer learning excluding yellow"]},{"metadata":{"id":"wGePhRqjtG3y","colab_type":"text"},"cell_type":"markdown","source":["## imports"]},{"metadata":{"id":"Q3YK-oxIDKk0","colab_type":"code","outputId":"ef4afac0-30f7-4b4e-d98f-76596f140173","executionInfo":{"status":"ok","timestamp":1546152600583,"user_tz":480,"elapsed":2670,"user":{"displayName":"Gowtham Mallikarjuna","photoUrl":"","userId":"05531825206472754494"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os, shutil, gc, sys\n","import pandas as pd\n","import numpy as np\n","from time import time\n","from itertools import chain\n","from collections import Counter\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","from PIL import Image\n","import imgaug as ia\n","from imgaug import augmenters as iaa\n","import cv2\n","import matplotlib.pyplot as plt\n","import tqdm as tqdm\n","from time import time\n","from datetime import datetime as dt\n","\n","import keras\n","from keras.utils import Sequence\n","from keras.models import Sequential, load_model, Model\n","from keras.layers import Activation, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Concatenate\n","from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,LearningRateScheduler,CSVLogger\n","from keras import metrics\n","from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n","from keras import backend as K\n","from tensorflow import set_random_seed\n","import tensorflow as tf\n","\n","root_dir = '/home/tensor/content'\n","project_dir = os.path.join(root_dir,'protein')\n","train_path = os.path.join(project_dir,'train')\n","test_path = os.path.join(project_dir,'test')\n","\n","train = pd.read_csv(os.path.join(project_dir,'train.csv'))\n","sample_submission = pd.read_csv(os.path.join(project_dir,'sample_submission.csv'))\n","\n","\n","BATCH_SIZE = 16\n","SEED = 777\n","INPUT_SHAPE = (299, 299, 3)\n","DEBUG = True\n","THRESHOLD = 0.05\n","ia.seed(SEED)\n","\n","VAL_RATIO = 0.1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"o3hZaldz0A_K","colab_type":"text"},"cell_type":"markdown","source":["try this - https://www.kaggle.com/kwentar/two-branches-xception-lb-0-3 .\n","\n","densenet 169 https://github.com/flyyufelix/DenseNet-Keras/blob/master/densenet169.py\n"]},{"metadata":{"id":"QH3r1Jqjc-bJ","colab_type":"text"},"cell_type":"markdown","source":["## preprocess"]},{"metadata":{"id":"00sqtLskE8Cv","colab_type":"code","colab":{}},"cell_type":"code","source":["def getTrainDataset():\n","  paths = []\n","  labels =[]\n","  \n","  for name, lbl in zip(train['Id'],train['Target'].str.split(' ')):\n","    y = np.zeros(28)\n","    for key in lbl:\n","      y[int(key)]=1\n","    paths.append(os.path.join(train_path,name))\n","    labels.append(y)\n","  return np.array(paths), np.array(labels)\n","\n","def getTestDataset():\n","    \n","    path_to_test = test_path\n","    data = sample_submission\n","\n","    paths = []\n","    labels = []\n","    \n","    for name in data['Id']:\n","        y = np.ones(28)\n","        paths.append(os.path.join(path_to_test, name))\n","        labels.append(y)\n","\n","    return np.array(paths), np.array(labels)\n","  \n","  \n","  \n","  \n","class ProteinDataGenerator(keras.utils.Sequence):\n","            \n","    def __init__(self, paths, labels, batch_size, shape, shuffle = False, use_cache = False, augment = False):\n","        self.paths, self.labels = paths, labels\n","        self.batch_size = batch_size\n","        self.shape = shape\n","        self.shuffle = shuffle\n","        self.use_cache = use_cache\n","        self.augment = augment\n","        if use_cache == True:\n","            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], shape[2]), dtype=np.float16)\n","            self.is_cached = np.zeros((paths.shape[0]))\n","        self.on_epoch_end()\n","    \n","    def __len__(self):\n","        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n","    \n","    def __getitem__(self, idx):\n","        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n","\n","        paths = self.paths[indexes]\n","        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n","        # Generate data\n","        if self.use_cache == True:\n","            X = self.cache[indexes]\n","            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n","                image = self.__load_image(path)\n","                self.is_cached[indexes[i]] = 1\n","                self.cache[indexes[i]] = image\n","                X[i] = image\n","        else:\n","            for i, path in enumerate(paths):\n","                X[i] = self.__load_image(path)\n","\n","        y = self.labels[indexes]\n","                \n","        if self.augment == True:\n","            seq = iaa.Sequential([\n","                iaa.OneOf([\n","                    iaa.Fliplr(0.5), # horizontal flips\n","                    iaa.Crop(percent=(0, 0.1)), # random crops\n","                    # Small gaussian blur with random sigma between 0 and 0.5.\n","                    # But we only blur about 50% of all images.\n","                    iaa.Sometimes(0.5,\n","                        iaa.GaussianBlur(sigma=(0, 0.5))\n","                    ),\n","                    # Strengthen or weaken the contrast in each image.\n","                    iaa.ContrastNormalization((0.75, 1.5)),\n","                    # Add gaussian noise.\n","                    # For 50% of all images, we sample the noise once per pixel.\n","                    # For the other 50% of all images, we sample the noise per pixel AND\n","                    # channel. This can change the color (not only brightness) of the\n","                    # pixels.\n","                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n","                    # Make some images brighter and some darker.\n","                    # In 20% of all cases, we sample the multiplier once per channel,\n","                    # which can end up changing the color of the images.\n","                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n","                    # Apply affine transformations to each image.\n","                    # Scale/zoom them, translate/move them, rotate them and shear them.\n","                    iaa.Affine(\n","                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n","                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n","                        rotate=(-180, 180),\n","                        shear=(-8, 8)\n","                    )\n","                ])], random_order=True)\n","\n","            X = np.concatenate((X, seq.augment_images(X), seq.augment_images(X), seq.augment_images(X)), 0)\n","            y = np.concatenate((y, y, y, y), 0)\n","        \n","        return X, y\n","    \n","    def on_epoch_end(self):\n","        \n","        # Updates indexes after each epoch\n","        self.indexes = np.arange(len(self.paths))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __iter__(self):\n","        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n","        for item in (self[i] for i in range(len(self))):\n","            yield item\n","          \n","            \n","    def __load_image(self, path):\n","        R = Image.open(path + '_red.png')\n","        G = Image.open(path + '_green.png')\n","        B = Image.open(path + '_blue.png')\n","#         Y = Image.open(path + '_yellow.png')\n","\n","        im = np.stack((\n","            np.array(R), \n","            np.array(G), \n","            np.array(B)\n","#             ,np.array(Y)\n","                     ),-1)\n","\n","        \n","        im = cv2.resize(im, (INPUT_SHAPE[0], INPUT_SHAPE[1]))\n","        im = np.divide(im, 255)\n","        return im\n","    \n","paths, labels = getTrainDataset()\n","train_generator = ProteinDataGenerator(paths, labels, BATCH_SIZE, INPUT_SHAPE)\n","\n","def f1(y_true, y_pred):\n","    y_pred = K.round(y_pred)\n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n","    return K.mean(f1)\n","\n","def f1_loss(y_true, y_pred):\n","    \n","    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n","    return 1-K.mean(f1)\n","  \n","paths, labels = getTrainDataset()\n","keys = np.arange(paths.shape[0], dtype=np.int)  \n","np.random.seed(SEED)\n","np.random.shuffle(keys)\n","lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n","\n","\n","pathsTrain = paths[0:lastTrainIndex]\n","labelsTrain = labels[0:lastTrainIndex]\n","pathsVal = paths[lastTrainIndex:]\n","labelsVal = labels[lastTrainIndex:]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DpgCootddB0P","colab_type":"text"},"cell_type":"markdown","source":["## transfer learning"]},{"metadata":{"id":"3ky3-Q0ufcOC","colab_type":"code","colab":{}},"cell_type":"code","source":["def create_model(BASE_MODEL,optimizer,turn_off=False):\n","  if BASE_MODEL=='VGG16':\n","      from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n","  elif BASE_MODEL=='vgg19':\n","      from keras.applications.vgg19 import VGG19 as PTModel, preprocess_input\n","  elif BASE_MODEL=='ResNet50':\n","      from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n","  elif BASE_MODEL=='InceptionV3':\n","      from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n","  elif BASE_MODEL=='Xception':\n","      from keras.applications.xception import Xception as PTModel, preprocess_input\n","  elif BASE_MODEL=='DenseNet169': \n","      from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n","  elif BASE_MODEL=='DenseNet121':\n","      from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n","  else:\n","      raise ValueError('Unknown model: {}'.format(BASE_MODEL))\n","  \n","  keras.backend.set_learning_phase(1)\n","  \n","  img_rows, img_cols, img_channel = INPUT_SHAPE\n","  base_model = PTModel(weights='imagenet'\n","                     ,include_top=False, input_shape=(img_rows, img_cols, img_channel))\n","\n","  add_model = Sequential()\n","  add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n","  add_model.add(Dense(128, activation='relu'))\n","  add_model.add(Dense(28, activation='sigmoid'))\n","\n","  model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n","\n","\n","#   for layer in base_model.layers:\n","#       layer.trainable = False\n","\n","#       if layer.name.startswith('bn'):\n","#           layer.call(layer.input, training=False)\n","\n","#   base_model.layers[-2].trainable = True\n","#   base_model.layers[-1].trainable = True\n","\n","  model.compile(loss='binary_crossentropy', \n","                optimizer=optimizer,\n","                metrics=['accuracy',f1])\n","  return model\n","\n","def transfer_learning(model,BASE_MODEL,epoch=4 ,batch_size=64):\n","  \n","  datetime_now = dt.now().strftime(\"%Y%m%d_%H%M_\")\n","  \n","  check_point_name = datetime_now + BASE_MODEL + '.model'\n","  check_point_name = os.path.join(project_dir,check_point_name)\n","  model_weights = datetime_now + BASE_MODEL + '.h5'\n","  model_weights = os.path.join(project_dir,model_weights)\n","  log_file = datetime_now + '_log.csv'\n","  log_file = os.path.join(project_dir,log_file)\n","  \n","  train_generator = ProteinDataGenerator(pathsTrain, labelsTrain, BATCH_SIZE, INPUT_SHAPE)\n","  validation_generator = ProteinDataGenerator(pathsVal, labelsVal, BATCH_SIZE, INPUT_SHAPE)  \n","  \n","#   STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n","#   STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n","    \n","  STEP_SIZE_TRAIN=pathsTrain.shape[0]//train_generator.batch_size\n","  STEP_SIZE_VALID=pathsTrain.shape[0]//validation_generator.batch_size\n","  \n","  reduceLROnPlato = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='min')\n","  earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=8, verbose=1, mode='auto')\n","  checkPoint = ModelCheckpoint(check_point_name, monitor='val_acc', save_best_only=True)\n","  csv_logger = CSVLogger(log_file, append=True, separator=';')\n","  \n","  history = model.fit_generator(generator=train_generator,\n","                      steps_per_epoch=STEP_SIZE_TRAIN,\n","                      validation_data=validation_generator,\n","                      use_multiprocessing=True,\n","                      epochs=epoch,\n","                      validation_steps=STEP_SIZE_VALID,\n","                     callbacks=[csv_logger,checkPoint,reduceLROnPlato, earlyStopping])\n","#   model.save_weights(model_weights)\n","  \n","  return history, model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ERR6nYYDkmyd","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","optimizer = SGD(lr=1e-2, momentum=0.9)\n","# model = create_model('DenseNet169', optimizer, batch_size = 16, turn_off=False)\n","\n","# saved_model=[f for f in os.listdir(project_dir) if f.endswith('.model')][-1]\n","# model = load_model(saved_model, custom_objects={'f1': f1})\n","\n","history, DenseNet169_model = transfer_learning(model,'DenseNet169',epoch=4,batch_size=16)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JEKKPSdrZziH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"1bea3925-40ed-44cb-fd00-d2fd979ead01","executionInfo":{"status":"ok","timestamp":1546153704829,"user_tz":480,"elapsed":1095281,"user":{"displayName":"Gowtham Mallikarjuna","photoUrl":"","userId":"05531825206472754494"}}},"cell_type":"code","source":["%%time\n","saved_model=max([f for f in os.listdir(project_dir) if f.endswith('.model')])\n","model = load_model(project_dir+'/'+saved_model, custom_objects={'f1': f1})\n","\n","history, DenseNet169_model = transfer_learning(model,'DenseNet169',epoch=1)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/1\n","1747/1747 [==============================] - 1014s 581ms/step - loss: 0.1059 - acc: 0.9627 - f1: 0.1905 - val_loss: 0.1092 - val_acc: 0.9621 - val_f1: 0.1823\n","CPU times: user 16min 49s, sys: 5min 54s, total: 22min 43s\n","Wall time: 18min 15s\n"],"name":"stdout"}]},{"metadata":{"id":"tXzSajJwaDtl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3A-Q88ChdGux","colab_type":"text"},"cell_type":"markdown","source":["## submit"]},{"metadata":{"id":"QA9B8FGPBx0a","colab_type":"code","colab":{}},"cell_type":"code","source":["saved_model=max([f for f in os.listdir(project_dir) if f.endswith('.model')])\n","model = load_model(project_dir+'/'+saved_model, custom_objects={'f1': f1})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tB8sV4wrgImu","colab_type":"code","outputId":"95cf9efe-ca91-4716-9003-ed265b0cae20","executionInfo":{"status":"ok","timestamp":1546150802986,"user_tz":480,"elapsed":183978,"user":{"displayName":"Gowtham Mallikarjuna","photoUrl":"","userId":"05531825206472754494"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["%%time\n","pathsTest, labelsTest = getTestDataset()\n","\n","testg = ProteinDataGenerator(pathsTest, labelsTest, BATCH_SIZE, INPUT_SHAPE)\n","P = np.zeros((pathsTest.shape[0], 28))\n","for i in tqdm.tqdm(range(len(testg))):\n","    images, labels = testg[i]\n","    score = model.predict(images)\n","    P[i*BATCH_SIZE:i*BATCH_SIZE+score.shape[0]] = score\n","    \n","PP = np.array(P)\n","prediction = []\n","\n","for row in tqdm.tqdm(range(sample_submission.shape[0])):\n","    \n","    str_label = ''\n","    \n","    for col in range(PP.shape[1]):\n","        if(PP[row, col] < 0.25):   # to account for losing TP is more costly than decreasing FP\n","            #print(PP[row])\n","            str_label += ''\n","        else:\n","            str_label += str(col) + ' '\n","    prediction.append(str_label.strip())\n","    \n","sample_submission['Predicted'] = np.array(prediction)\n","sample_submission.to_csv(project_dir+'/DenseNet169_model3.csv', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 732/732 [03:03<00:00,  4.78it/s]\n","100%|██████████| 11702/11702 [00:00<00:00, 99317.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 2min 15s, sys: 21 s, total: 2min 36s\n","Wall time: 3min 3s\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"metadata":{"id":"UQzV-hWeBwXV","colab_type":"code","colab":{}},"cell_type":"code","source":["os.chdir(project_dir)\n","sample_submission['Predicted'] = P\n","sample_submission.to_csv('DenseNet169_model2.csv', index=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iduK7pRQLOKy","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}